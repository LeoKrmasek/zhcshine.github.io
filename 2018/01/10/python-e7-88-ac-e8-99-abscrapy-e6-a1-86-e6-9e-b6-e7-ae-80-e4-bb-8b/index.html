<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>python爬虫scrapy框架简介 | zhuohc.com</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试 Scrapy主要">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫scrapy框架简介">
<meta property="og:url" content="http://www.zhuohc.com/2018/01/10/python-e7-88-ac-e8-99-abscrapy-e6-a1-86-e6-9e-b6-e7-ae-80-e4-bb-8b/index.html">
<meta property="og:site_name" content="zhuohc.com">
<meta property="og:description" content="Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试 Scrapy主要">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-07-23T05:51:43.850Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python爬虫scrapy框架简介">
<meta name="twitter:description" content="Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试 Scrapy主要">
  
    <link rel="alternate" href="/atom.xml" title="zhuohc.com" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">zhuohc.com</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">我的个人网站</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://www.zhuohc.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-python-e7-88-ac-e8-99-abscrapy-e6-a1-86-e6-9e-b6-e7-ae-80-e4-bb-8b" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/10/python-e7-88-ac-e8-99-abscrapy-e6-a1-86-e6-9e-b6-e7-ae-80-e4-bb-8b/" class="article-date">
  <time datetime="2018-01-10T07:44:12.000Z" itemprop="datePublished">2018-01-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/后端/">后端</a>►<a class="article-category-link" href="/categories/后端/运维/">运维</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      python爬虫scrapy框架简介
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试</p>
<h3 id="Scrapy主要包括了以下组件："><a href="#Scrapy主要包括了以下组件：" class="headerlink" title="Scrapy主要包括了以下组件："></a>Scrapy主要包括了以下组件：</h3><ol>
<li>引擎(Scrapy): 用来处理整个系统的数据流处理, 触发事务(框架核心)</li>
<li>调度器(Scheduler): 用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL（抓取网页的网址或者说是链接）的优先队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址</li>
<li>下载器(Downloader): 用于下载网页内容, 并将网页内容返回给蜘蛛(Scrapy下载器是建立在twisted这个高效的异步模型上的)</li>
<li>爬虫(Spiders): 爬虫是主要干活的, 用于从特定的网页中提取自己需要的信息, 即所谓的实体(Item)。用户也可以从中提取出链接,让Scrapy继续抓取下一个页面</li>
<li>项目管道(Pipeline): 负责处理爬虫从网页中抽取的实体，主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。当页面被爬虫解析后，将被发送到项目管道，并经过几个特定的次序处理数据。</li>
<li>下载器中间件(Downloader Middlewares): 位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应。</li>
<li>爬虫中间件(Spider Middlewares): 介于Scrapy引擎和爬虫之间的框架，主要工作是处理蜘蛛的响应输入和请求输出。</li>
<li>调度中间件(Scheduler Middewares): 介于Scrapy引擎和调度之间的中间件，从Scrapy引擎发送到调度的请求和响应。</li>
</ol>
<h3 id="Scrapy运行流程大概如下："><a href="#Scrapy运行流程大概如下：" class="headerlink" title="Scrapy运行流程大概如下："></a>Scrapy运行流程大概如下：</h3><p>首先，引擎从调度器中取出一个链接(URL)用于接下来的抓取 引擎把URL封装成一个请求(Request)传给下载器，下载器把资源下载下来，并封装成应答包(Response) 然后，爬虫解析Response 若是解析出实体（Item）,则交给实体管道进行进一步的处理。 若是解析出的是链接（URL）,则把URL交给Scheduler等待抓取</p>
<h3 id="备忘"><a href="#备忘" class="headerlink" title="备忘"></a>备忘</h3><h4 id="使用Selector提取数据"><a href="#使用Selector提取数据" class="headerlink" title="使用Selector提取数据"></a>使用Selector提取数据</h4><h4 id="xpath语法和基本函数"><a href="#xpath语法和基本函数" class="headerlink" title="xpath语法和基本函数"></a>xpath语法和基本函数</h4><pre><code>/
.
..
ELEMENT
//ELEMENT
*
text
@ALTER
@*
position()
last()
string()</code></pre><h4 id="css选择器"><a href="#css选择器" class="headerlink" title="css选择器"></a>css选择器</h4><pre><code>*
E
E1&gt;E2
E1+E2
.CLASS
#ID
[ATTR]
[ATTR=VALUE]
E:nth-child(n)
E:first-child</code></pre><h4 id="使用Item和Field封装数据"><a href="#使用Item和Field封装数据" class="headerlink" title="使用Item和Field封装数据"></a>使用Item和Field封装数据</h4><p>Field(serializer=lambda)设置存储数据</p>
<h4 id="使用Item-Pipeline处理数据"><a href="#使用Item-Pipeline处理数据" class="headerlink" title="使用Item Pipeline处理数据"></a>使用Item Pipeline处理数据</h4><p>修改数据,过滤重复数据,将数据写入到数据库等</p>
<h4 id="LinkExtractor提取链接"><a href="#LinkExtractor提取链接" class="headerlink" title="LinkExtractor提取链接"></a>LinkExtractor提取链接</h4><pre><code>LinkExtractor参数
allow 允许链接
deny 拒绝链接
allow_domains 允许域名
deny_domains 拒绝域名
restrict_xpaths 允许xpath链接
restrict_css 允许css选择器链接</code></pre><h4 id="Exporter导出数据"><a href="#Exporter导出数据" class="headerlink" title="Exporter导出数据"></a>Exporter导出数据</h4><p>默认包含以下</p>
<pre><code>JSON, JSON LINES, CSV, XML, PICKLE, MARSHAL</code></pre><p>可配置导出格式和存放文件地址, 可自定义导出格式,例如xls</p>
<h4 id="下载文件和图片"><a href="#下载文件和图片" class="headerlink" title="下载文件和图片"></a>下载文件和图片</h4><p>FIlesPipeline</p>
<pre><code>setting.py
ITEM_PIPELINES = {&apos;scrapy.pipelines.files.FilesPipeline&apos;: 1}
FILES_STORE = &apos;/home/hanchang/download&apos;</code></pre><p>ImagesPipeline</p>
<h4 id="模拟登录"><a href="#模拟登录" class="headerlink" title="模拟登录"></a>模拟登录</h4><p>使用FromRequest ORC识别验证码:pillow, pytesseract 付费网络平台识别 人工识别:爬取登录页面的验证码图片,调用Image.show方法,肉眼识别并输入到内置的input函数中 Cookie登录: 获取浏览器的cookie值(browsercookie包), 利用BrowserCookiesMiddleware将获取的cookie值添加到CookieJar中</p>
<h4 id="动态页面抓取"><a href="#动态页面抓取" class="headerlink" title="动态页面抓取"></a>动态页面抓取</h4><p>Splash是Scrapy官方推荐的javascript渲染引擎, Webkit无界面浏览器</p>
<pre><code># 安装
sudo apt-get install docker
sudo docker pull scrapinghub/splash
sudo docker run -p 8050:8050 -p 8051:8051 scrapinghub/splash</code></pre><p>splash常见服务端点 <a href="http://localhost:8050/render.html" target="_blank" rel="noopener">http://localhost:8050/render.html</a> GET/POST 返回html 参数: url, timeout, proxy, wait, images, js_source <a href="http://localhost:8050/excute" target="_blank" rel="noopener">http://localhost:8050/excute</a> 传递模拟的动作给splash,例如等待页面渲染，执行代码，等等</p>
<h5 id="scrapy使用splash"><a href="#scrapy使用splash" class="headerlink" title="scrapy使用splash"></a>scrapy使用splash</h5><pre><code>安装
pip install scrapy-splash


setting.py
# splash服务器地址
SPLASH_URL = &apos;http://localhost:8050&apos;
# 开启splash的两个下载中间件并调整HttpCompressionMiddleware的次序
DOWNLOADER_MIDDLEWARES = {
    &apos;scrapy_splash.SplashCookiesMiddleware&apos;: 723,
        &apos;scrapy_splash.SplashMiddleware&apos;: 725,
        &apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&apos;: 810,
}
# 过滤去重函数
DUPEFILTER_CLASS = &apos;scrapy_splash.SplashAwareDupeFilter&apos;,
# 用户支持cahce_args
SPIDER_MIDDLEWARES = {
  &apos;scrapy_splash.SplashDeduplicateArgsMiddleware&apos;: 100,
}</code></pre><h4 id="分布式爬取"><a href="#分布式爬取" class="headerlink" title="分布式爬取"></a>分布式爬取</h4><p>使用scrapy-redis</p>
<pre><code># 安装
pip install scrapy
pip install scrapy-redis


# 在配置文件setting.py中添加scrapy-redis相关信息
# redis服务器
REDIS_URL = &apos;redis://127.0.0.1:6379&apos;
# 使用scrapy_redis调度器替代原生调度器
SCHEDULER = &apos;scrapy_redis.scheduler.Scheduler&apos;
# 使用scrapy_redis的RFPDupeFilter作为去重过滤器
DUPEFILTER_CLASS = &apos;scrapy_redis.dupefilter.RFPDupeFilter&apos;
# 将爬取的数据存储到redis中
ITEM_PIPELINES = {
    &apos;scrapy_redis.pipelines.RedisPipeline&apos;: 300,
}
# 爬虫停止后,保留/清除Reids中的请求队列以及去重集合
SCHEDULER_PERSIST = False


# 修改爬虫spider.py
from scrapy_redis.spiders import RedisSpider

class BookSpider(RedisSpider):

    # 注释start_urls
    # start_urls = []


# 手动添加start_urls
redis-cli -h 127.0.0.1
lpush books:start_urls &apos;http://www.books.com/&apos;</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.zhuohc.com/2018/01/10/python-e7-88-ac-e8-99-abscrapy-e6-a1-86-e6-9e-b6-e7-ae-80-e4-bb-8b/" data-id="cjyfelqwd002jcta40ckkwqvd" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/01/11/redis-e5-9f-ba-e7-a1-80/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Redis基础
        
      </div>
    </a>
  
  
    <a href="/2017/11/22/e6-9c-80-e6-96-b0-e5-9c-a8linux-ubuntu-e4-b8-ad-e5-ae-89-e8-a3-85qq-e7-9a-84-e5-8a-9e-e6-b3-95/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">最新在linux/ubuntu中安装qq的办法</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/办公/">办公</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/办公/后端/">后端</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/办公/后端/运维/">运维</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/办公/运维/">运维</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/后端/">后端</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/后端/运维/">运维</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDE/">IDE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bash/">bash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/django/">django</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/javascript/">javascript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php/">php</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ubuntu/">ubuntu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/windows/">windows</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/微信/">微信</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据库/">数据库</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/IDE/" style="font-size: 12.5px;">IDE</a> <a href="/tags/bash/" style="font-size: 10px;">bash</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/javascript/" style="font-size: 10px;">javascript</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/mysql/" style="font-size: 12.5px;">mysql</a> <a href="/tags/php/" style="font-size: 15px;">php</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/redis/" style="font-size: 10px;">redis</a> <a href="/tags/ubuntu/" style="font-size: 12.5px;">ubuntu</a> <a href="/tags/windows/" style="font-size: 17.5px;">windows</a> <a href="/tags/微信/" style="font-size: 10px;">微信</a> <a href="/tags/数据库/" style="font-size: 10px;">数据库</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/07/23/测试blog/">测试blog</a>
          </li>
        
          <li>
            <a href="/2019/07/23/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/11/17/e5-9c-a8bash-e6-98-be-e7-a4-bagit-e5-88-86-e6-94-af-e4-bf-a1-e6-81-af/">在bash显示git分支信息</a>
          </li>
        
          <li>
            <a href="/2018/11/16/zabbix-e5-ae-89-e8-a3-85-e5-8f-8a-e4-bd-bf-e7-94-a8/">zabbix安装及使用</a>
          </li>
        
          <li>
            <a href="/2018/11/14/centos7-2-e5-ae-89-e8-a3-85-e4-bd-bf-e7-94-a8openresty/">centos7.2安装使用openResty</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 www.zhuohc.om<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>